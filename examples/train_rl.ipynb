{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(..)\n",
    "import gentrl\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "from moses.metrics import mol_passes_filters, QED, SA, logP\n",
    "from moses.metrics.utils import get_n_rings, get_mol\n",
    "from moses.utils import disable_rdkit_log\n",
    "disable_rdkit_log()\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = gentrl.RNNEncoder(latent_size=50)\n",
    "dec = gentrl.DilConvDecoder(latent_input_size=50)\n",
    "model = gentrl.GENTRL(enc, dec, 50 * [('c', 20)], [('c', 20)], beta=0.001)\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('pretrained_model/')\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward 1: Baseline Training - only penalized_logP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_rings_6(mol):\n",
    "    r = mol.GetRingInfo()\n",
    "    return len([x for x in r.AtomRings() if len(x) > 6])\n",
    "\n",
    "\n",
    "def penalized_logP(mol_or_smiles, masked=False, default=-5):\n",
    "    mol = get_mol(mol_or_smiles)\n",
    "    if mol is None:\n",
    "        return default\n",
    "    reward = logP(mol) - SA(mol) - get_num_rings_6(mol)\n",
    "    if masked and not mol_passes_filters(mol):\n",
    "        return default\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward 2: Promoting Diversity: Penalized logP + Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diversity(mol, reference_mol_fps):\n",
    "    mol_fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024) \n",
    "    max_similarity = max(DataStructs.BulkTanimotoSimilarity(mol_fp, reference_mol_fps))\n",
    "    novelty = 1 - max_similarity\n",
    "    return novelty\n",
    "\n",
    "def penalized_logP_diversity(mol_or_smiles, reference_mol_fps, masked=False, default=-5):\n",
    "    mol = get_mol(mol_or_smiles)\n",
    "    if mol is None:\n",
    "        return default\n",
    "    reward = logP(mol) - SA(mol) - get_num_rings_6(mol)\n",
    "    diversity = calculate_diversity(mol, reference_mol_fps)\n",
    "    if masked and not mol_passes_filters(mol):\n",
    "        return default\n",
    "    total_reward = reward + diversity\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pd.read_csv('../data/train_plogp_plogpm.csv') #SMILES training set molecules\n",
    "reference_mols = [Chem.MolFromSmiles(smiles) for smiles in ref['smiles'].iloc[:5000]]\n",
    "reference_mol_fps = [AllChem.GetMorganFingerprintAsBitVect(ref_mol, 2, nBits=1024) for ref_mol in reference_mols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward 3: Targeted Molecule Design: Penalized logP + Diversity + Substructure Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substructure(mol):\n",
    "    melatonin_mol = Chem.MolFromSmiles('CC(=O)NCCC1=CNC2=C1C=C(C=C2)OC')\n",
    "    return mol.HasSubstructMatch(melatonin_mol)\n",
    "    # true if yes false if no\n",
    "\n",
    "def penalized_logP_diversity_substructure(mol_or_smiles, reference_mol_fps, masked=False, default=-5):\n",
    "    mol = get_mol(mol_or_smiles)\n",
    "    if mol is None or not substructure(mol):\n",
    "        return default\n",
    "    reward = logP(mol) - SA(mol) - get_num_rings_6(mol)\n",
    "    diversity = calculate_diversity(mol, reference_mol_fps)\n",
    "    if masked and not mol_passes_filters(mol):\n",
    "        return default\n",
    "    total_reward = reward + diversity\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_as_rl(lambda mol: penalized_logP_diversity_substructure(mol, reference_mol_fps=reference_mol_fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p rl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./rl_model/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
